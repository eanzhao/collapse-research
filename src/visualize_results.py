# src/visualize_results.py
"""
å®éªŒç»“æœå¯è§†åŒ–
"""
import sys
sys.path.append('.')

import json
import os
import statistics
from utils import THEORETICAL_BOUND

# å°è¯•å¯¼å…¥matplotlibï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ–‡æœ¬è¾“å‡º
try:
    import matplotlib.pyplot as plt
    import numpy as np
    HAS_MATPLOTLIB = True
except ImportError:
    HAS_MATPLOTLIB = False
    print("âš ï¸  matplotlibæœªå®‰è£…ï¼Œå°†ä½¿ç”¨æ–‡æœ¬è¾“å‡ºæ¨¡å¼")

def load_results(filename: str = "results/experiment_results.json"):
    """åŠ è½½å®éªŒç»“æœ"""
    if not os.path.exists(filename):
        print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶ {filename}")
        print("è¯·å…ˆè¿è¡Œ collapse_vs_dp_experiment.py ç”Ÿæˆå®éªŒç»“æœ")
        return None
    
    with open(filename, 'r') as f:
        data = json.load(f)
    
    return data.get('results', data)  # å…¼å®¹æ–°æ—§æ ¼å¼

def text_visualization(results):
    """çº¯æ–‡æœ¬å¯è§†åŒ–"""
    print("\n" + "="*60)
    print("ğŸ“Š å®éªŒç»“æœå¯è§†åŒ–ï¼ˆæ–‡æœ¬æ¨¡å¼ï¼‰")
    print("="*60)
    
    # æŒ‰è§„æ¨¡åˆ†ç»„
    by_size = {}
    for r in results:
        n = r['n']
        if n not in by_size:
            by_size[n] = []
        by_size[n].append(r['approximation_ratio'])
    
    # 1. è¿‘ä¼¼æ¯”åˆ†å¸ƒ
    print("\n### è¿‘ä¼¼æ¯”åˆ†å¸ƒ ###")
    print(f"ç†è®ºä¸‹ç•Œ: {THEORETICAL_BOUND:.3f}")
    print("\nè§„æ¨¡  æœ€å°å€¼  Q1     ä¸­ä½æ•°  Q3     æœ€å¤§å€¼  å¹³å‡å€¼")
    print("-" * 55)
    
    for n in sorted(by_size.keys()):
        ratios = by_size[n]
        if len(ratios) >= 4:
            q1, q2, q3 = statistics.quantiles(ratios, n=4)
        else:
            q1 = q2 = q3 = statistics.median(ratios)
        
        print(f"{n:4d}  {min(ratios):.3f}  {q1:.3f}  {q2:.3f}  "
              f"{q3:.3f}  {max(ratios):.3f}  {statistics.mean(ratios):.3f}")
    
    # 2. é€Ÿåº¦æå‡è¶‹åŠ¿
    print("\n### é€Ÿåº¦æå‡è¶‹åŠ¿ ###")
    speed_by_size = {}
    for r in results:
        n = r['n']
        if n not in speed_by_size:
            speed_by_size[n] = []
        speed_by_size[n].append(r['speedup'])
    
    print("\nè§„æ¨¡  å¹³å‡é€Ÿåº¦æå‡  æœ€å¤§é€Ÿåº¦æå‡")
    print("-" * 35)
    for n in sorted(speed_by_size.keys()):
        speeds = speed_by_size[n]
        print(f"{n:4d}  {statistics.mean(speeds):10.1f}x  {max(speeds):10.1f}x")
    
    # 3. è¿‘ä¼¼æ¯”ç›´æ–¹å›¾ï¼ˆASCII artï¼‰
    print("\n### è¿‘ä¼¼æ¯”åˆ†å¸ƒç›´æ–¹å›¾ ###")
    all_ratios = [r['approximation_ratio'] for r in results]
    
    # åˆ›å»º10ä¸ªåŒºé—´
    min_ratio = min(all_ratios)
    max_ratio = max(all_ratios)
    bins = 10
    bin_width = (max_ratio - min_ratio) / bins
    
    histogram = [0] * bins
    for ratio in all_ratios:
        bin_idx = min(int((ratio - min_ratio) / bin_width), bins - 1)
        histogram[bin_idx] += 1
    
    max_count = max(histogram)
    print(f"\nèŒƒå›´: [{min_ratio:.3f}, {max_ratio:.3f}]")
    print("é¢‘ç‡åˆ†å¸ƒ:")
    
    for i, count in enumerate(histogram):
        start = min_ratio + i * bin_width
        end = start + bin_width
        bar = 'â–ˆ' * int(50 * count / max_count)
        print(f"[{start:.3f}-{end:.3f}] {bar} {count}")
    
    print(f"\nç†è®ºä¸‹ç•Œ {THEORETICAL_BOUND:.3f} â†‘")

def plot_approximation_ratios(results):
    """ç»˜åˆ¶è¿‘ä¼¼æ¯”åˆ†å¸ƒå›¾"""
    if not HAS_MATPLOTLIB:
        return
    
    # æŒ‰è§„æ¨¡åˆ†ç»„
    by_size = {}
    for r in results:
        n = r['n']
        if n not in by_size:
            by_size[n] = []
        by_size[n].append(r['approximation_ratio'])
    
    # å‡†å¤‡æ•°æ®
    sizes = sorted(by_size.keys())
    data = [by_size[n] for n in sizes]
    
    # åˆ›å»ºç®±çº¿å›¾
    plt.figure(figsize=(10, 6))
    bp = plt.boxplot(data, labels=[f'n={n}' for n in sizes], patch_artist=True)
    
    # è®¾ç½®é¢œè‰²
    for patch in bp['boxes']:
        patch.set_facecolor('lightblue')
    
    # æ·»åŠ ç†è®ºä¸‹ç•Œçº¿
    plt.axhline(y=THEORETICAL_BOUND, color='r', linestyle='--', 
                label=f'ç†è®ºä¸‹ç•Œ ({THEORETICAL_BOUND:.3f})')
    
    # æ·»åŠ å¹³å‡å€¼çº¿
    means = [statistics.mean(d) for d in data]
    plt.plot(range(1, len(sizes)+1), means, 'g^-', label='å¹³å‡å€¼')
    
    plt.xlabel('é—®é¢˜è§„æ¨¡')
    plt.ylabel('è¿‘ä¼¼æ¯”')
    plt.title('CollapseGPT è¿‘ä¼¼æ¯”åˆ†å¸ƒ')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    os.makedirs('results', exist_ok=True)
    plt.savefig('results/approximation_ratios.png', dpi=150)
    print("å·²ä¿å­˜: results/approximation_ratios.png")
    plt.show()

def plot_speedup_trend(results):
    """ç»˜åˆ¶é€Ÿåº¦æå‡è¶‹åŠ¿å›¾"""
    if not HAS_MATPLOTLIB:
        return
    
    # æŒ‰è§„æ¨¡åˆ†ç»„è®¡ç®—å¹³å‡å€¼
    by_size = {}
    for r in results:
        n = r['n']
        if n not in by_size:
            by_size[n] = []
        by_size[n].append(r['speedup'])
    
    sizes = sorted(by_size.keys())
    avg_speedups = [statistics.mean(by_size[n]) for n in sizes]
    max_speedups = [max(by_size[n]) for n in sizes]
    
    # ç»˜åˆ¶è¶‹åŠ¿å›¾
    plt.figure(figsize=(10, 6))
    plt.plot(sizes, avg_speedups, 'bo-', linewidth=2, markersize=8, label='å¹³å‡é€Ÿåº¦æå‡')
    plt.plot(sizes, max_speedups, 'r^--', linewidth=1, markersize=6, label='æœ€å¤§é€Ÿåº¦æå‡')
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (x, y) in enumerate(zip(sizes, avg_speedups)):
        plt.annotate(f'{y:.1f}x', (x, y), textcoords="offset points", 
                    xytext=(0,10), ha='center')
    
    plt.xlabel('é—®é¢˜è§„æ¨¡ (n)')
    plt.ylabel('é€Ÿåº¦æå‡å€æ•°')
    plt.title('CollapseGPT vs åŠ¨æ€è§„åˆ’ é€Ÿåº¦å¯¹æ¯”')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.yscale('log')  # ä½¿ç”¨å¯¹æ•°åæ ‡
    plt.tight_layout()
    
    plt.savefig('results/speedup_trend.png', dpi=150)
    print("å·²ä¿å­˜: results/speedup_trend.png")
    plt.show()

def plot_time_complexity(results):
    """éªŒè¯æ—¶é—´å¤æ‚åº¦"""
    if not HAS_MATPLOTLIB:
        return
    
    # æ”¶é›†æ—¶é—´æ•°æ®
    collapse_times = {}
    dp_times = {}
    
    for r in results:
        n = r['n']
        if n not in collapse_times:
            collapse_times[n] = []
            dp_times[n] = []
        collapse_times[n].append(r['collapse_time'])
        dp_times[n].append(r['dp_time'])
    
    sizes = sorted(collapse_times.keys())
    avg_collapse = [statistics.mean(collapse_times[n]) for n in sizes]
    avg_dp = [statistics.mean(dp_times[n]) for n in sizes]
    
    # å¯¹æ•°åæ ‡ç»˜å›¾
    plt.figure(figsize=(10, 6))
    
    # å®é™…æ—¶é—´
    plt.loglog(sizes, avg_collapse, 'bo-', label='CollapseGPT', linewidth=2, markersize=8)
    plt.loglog(sizes, avg_dp, 'ro-', label='åŠ¨æ€è§„åˆ’', linewidth=2, markersize=8)
    
    # æ·»åŠ ç†è®ºå¤æ‚åº¦å‚è€ƒçº¿
    n_array = np.array(sizes)
    # è°ƒæ•´ç³»æ•°ä½¿æ›²çº¿å¯¹é½
    c1 = avg_collapse[0] / (sizes[0] * np.log(sizes[0]))
    c2 = avg_dp[0] / (sizes[0] ** 2)
    
    plt.loglog(n_array, c1 * n_array * np.log(n_array), 'b--', 
               alpha=0.5, label='O(n log n) ç†è®º')
    plt.loglog(n_array, c2 * n_array**2, 'r--', 
               alpha=0.5, label='O(nÂ²) ç†è®º')
    
    plt.xlabel('é—®é¢˜è§„æ¨¡ (n)')
    plt.ylabel('è¿è¡Œæ—¶é—´ (ç§’)')
    plt.title('æ—¶é—´å¤æ‚åº¦éªŒè¯')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    
    plt.savefig('results/time_complexity.png', dpi=150)
    print("å·²ä¿å­˜: results/time_complexity.png")
    plt.show()

def plot_comprehensive_analysis(results):
    """ç»¼åˆåˆ†æå›¾"""
    if not HAS_MATPLOTLIB:
        return
    
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    
    # 1. è¿‘ä¼¼æ¯”vsè§„æ¨¡
    ax1 = axes[0, 0]
    by_size = {}
    for r in results:
        n = r['n']
        if n not in by_size:
            by_size[n] = {'ratios': [], 'speeds': [], 'losses': []}
        by_size[n]['ratios'].append(r['approximation_ratio'])
        by_size[n]['speeds'].append(r['speedup'])
        by_size[n]['losses'].append(r.get('value_loss_percent', 0))
    
    sizes = sorted(by_size.keys())
    avg_ratios = [statistics.mean(by_size[n]['ratios']) for n in sizes]
    
    ax1.plot(sizes, avg_ratios, 'bo-', linewidth=2, markersize=8)
    ax1.axhline(y=THEORETICAL_BOUND, color='r', linestyle='--', label='ç†è®ºä¸‹ç•Œ')
    ax1.set_xlabel('é—®é¢˜è§„æ¨¡')
    ax1.set_ylabel('å¹³å‡è¿‘ä¼¼æ¯”')
    ax1.set_title('è¿‘ä¼¼æ¯” vs é—®é¢˜è§„æ¨¡')
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    
    # 2. é€Ÿåº¦æå‡åˆ†å¸ƒ
    ax2 = axes[0, 1]
    all_speeds = [r['speedup'] for r in results]
    ax2.hist(all_speeds, bins=20, color='green', alpha=0.7, edgecolor='black')
    ax2.set_xlabel('é€Ÿåº¦æå‡å€æ•°')
    ax2.set_ylabel('é¢‘ç‡')
    ax2.set_title('é€Ÿåº¦æå‡åˆ†å¸ƒ')
    ax2.grid(True, alpha=0.3)
    
    # 3. ä»·å€¼æŸå¤±
    ax3 = axes[1, 0]
    avg_losses = [statistics.mean(by_size[n]['losses']) for n in sizes]
    ax3.bar(range(len(sizes)), avg_losses, tick_label=[f'n={n}' for n in sizes])
    ax3.set_xlabel('é—®é¢˜è§„æ¨¡')
    ax3.set_ylabel('å¹³å‡ä»·å€¼æŸå¤± (%)')
    ax3.set_title('ä»·å€¼æŸå¤±åˆ†æ')
    ax3.grid(True, alpha=0.3, axis='y')
    
    # 4. æ€§èƒ½é›·è¾¾å›¾
    ax4 = axes[1, 1]
    # è®¡ç®—ç»¼åˆæŒ‡æ ‡
    overall_ratio = statistics.mean(r['approximation_ratio'] for r in results)
    overall_speed = min(statistics.mean(r['speedup'] for r in results) / 100, 1)  # å½’ä¸€åŒ–
    overall_stability = 1 - statistics.stdev(r['approximation_ratio'] for r in results)
    theory_match = sum(1 for r in results if r['approximation_ratio'] >= THEORETICAL_BOUND) / len(results)
    
    categories = ['è¿‘ä¼¼æ¯”', 'é€Ÿåº¦æå‡', 'ç¨³å®šæ€§', 'ç†è®ºç¬¦åˆåº¦']
    values = [overall_ratio, overall_speed, overall_stability, theory_match]
    
    angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
    values += values[:1]
    angles += angles[:1]
    
    ax4.plot(angles, values, 'o-', linewidth=2, color='blue')
    ax4.fill(angles, values, alpha=0.25, color='blue')
    ax4.set_theta_offset(np.pi / 2)
    ax4.set_theta_direction(-1)
    ax4.set_xticks(angles[:-1])
    ax4.set_xticklabels(categories)
    ax4.set_ylim(0, 1)
    ax4.set_title('ç»¼åˆæ€§èƒ½è¯„ä¼°')
    ax4.grid(True)
    
    plt.tight_layout()
    plt.savefig('results/comprehensive_analysis.png', dpi=150)
    print("å·²ä¿å­˜: results/comprehensive_analysis.png")
    plt.show()

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š CollapseGPT å®éªŒç»“æœå¯è§†åŒ–")
    print("="*50)
    
    # åŠ è½½ç»“æœ
    results = load_results()
    if results is None:
        return
    
    print(f"å·²åŠ è½½ {len(results)} ä¸ªå®éªŒç»“æœ")
    
    # æ–‡æœ¬å¯è§†åŒ–ï¼ˆå§‹ç»ˆæ‰§è¡Œï¼‰
    text_visualization(results)
    
    # å›¾å½¢å¯è§†åŒ–ï¼ˆå¦‚æœæœ‰matplotlibï¼‰
    if HAS_MATPLOTLIB:
        print("\nç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        plot_approximation_ratios(results)
        plot_speedup_trend(results)
        plot_time_complexity(results)
        plot_comprehensive_analysis(results)
        print("\næ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ° results/ ç›®å½•")
    else:
        print("\næç¤ºï¼šå®‰è£… matplotlib å’Œ numpy å¯ä»¥ç”Ÿæˆæ›´ä¸°å¯Œçš„å¯è§†åŒ–å›¾è¡¨")
        print("è¿è¡Œ: pip install matplotlib numpy")

if __name__ == "__main__":
    main() 
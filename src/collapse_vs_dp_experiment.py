# src/collapse_vs_dp_experiment.py
"""
å¤§è§„æ¨¡å¯¹æ¯”å®éªŒï¼šCollapseGPT vs åŠ¨æ€è§„åˆ’
"""
import sys
sys.path.append('.')

import json
import os
import statistics
from typing import Dict, List
from utils import generate_random_items, PHI, THEORETICAL_BOUND
from collapse_gpt import collapse_knapsack
from dynamic_programming import dp_knapsack

def run_single_experiment(n: int, capacity_ratio: float = 0.5, seed: int = None) -> Dict:
    """è¿è¡Œå•æ¬¡å®éªŒ"""
    # ç”Ÿæˆéšæœºç‰©å“
    items = generate_random_items(n, seed=seed)
    
    # è®¾ç½®èƒŒåŒ…å®¹é‡ä¸ºæ€»é‡é‡çš„ä¸€å®šæ¯”ä¾‹
    total_weight = sum(item.weight for item in items)
    capacity = int(total_weight * capacity_ratio)
    
    # CollapseGPTæ±‚è§£
    collapse_items = items.copy()
    collapse_selected, collapse_time = collapse_knapsack(collapse_items, capacity)
    collapse_value = sum(item.value for item in collapse_selected)
    
    # åŠ¨æ€è§„åˆ’æ±‚è§£
    dp_items = items.copy()
    dp_selected, dp_time = dp_knapsack(dp_items, capacity)
    dp_value = sum(item.value for item in dp_selected)
    
    # è®¡ç®—æŒ‡æ ‡
    approximation_ratio = collapse_value / dp_value if dp_value > 0 else 0
    speedup = dp_time / collapse_time if collapse_time > 0 else float('inf')
    
    # é¢å¤–ç»Ÿè®¡
    avg_trace_length = sum(item.trace_length for item in collapse_selected) / len(collapse_selected) if collapse_selected else 0
    
    return {
        'n': n,
        'capacity': capacity,
        'collapse_value': collapse_value,
        'dp_value': dp_value,
        'value_loss': dp_value - collapse_value,
        'value_loss_percent': (dp_value - collapse_value) / dp_value * 100 if dp_value > 0 else 0,
        'approximation_ratio': approximation_ratio,
        'collapse_time': collapse_time,
        'dp_time': dp_time,
        'speedup': speedup,
        'collapse_items': len(collapse_selected),
        'dp_items': len(dp_selected),
        'items_diff': len(dp_selected) - len(collapse_selected),
        'avg_trace_length': avg_trace_length,
        'memory_ratio': (n + 1) * (capacity + 1) / n  # DPå†…å­˜ vs Collapseå†…å­˜
    }

def run_experiments(sizes: List[int], trials: int = 10) -> List[Dict]:
    """è¿è¡Œå¤šç»„å®éªŒ"""
    results = []
    
    print("ğŸš€ å¼€å§‹å®éªŒ...\n")
    
    for n in sizes:
        print(f"è¿è¡Œ n={n} çš„å®éªŒ...")
        size_results = []
        
        for trial in range(trials):
            result = run_single_experiment(n, seed=trial)
            results.append(result)
            size_results.append(result)
            
            # å®æ—¶æ˜¾ç¤ºè¿›åº¦
            if (trial + 1) % 5 == 0:
                avg_ratio = statistics.mean(r['approximation_ratio'] for r in size_results)
                avg_speedup = statistics.mean(r['speedup'] for r in size_results)
                print(f"  è¿›åº¦: {trial+1}/{trials} - å¹³å‡è¿‘ä¼¼æ¯”: {avg_ratio:.3f}, å¹³å‡åŠ é€Ÿ: {avg_speedup:.1f}x")
        
        # æ˜¾ç¤ºè¯¥è§„æ¨¡çš„æ€»ç»“
        ratios = [r['approximation_ratio'] for r in size_results]
        speedups = [r['speedup'] for r in size_results]
        print(f"  å®Œæˆ! è¿‘ä¼¼æ¯”: {statistics.mean(ratios):.3f} Â± {statistics.stdev(ratios):.3f}, "
              f"åŠ é€Ÿ: {statistics.mean(speedups):.1f}x\n")
    
    return results

def analyze_results(results: List[Dict]):
    """åˆ†æå®éªŒç»“æœ"""
    print("\n" + "="*70)
    print("ğŸ“Š å®éªŒç»“æœåˆ†æ")
    print("="*70)
    
    # æŒ‰è§„æ¨¡åˆ†ç»„
    by_size = {}
    for r in results:
        n = r['n']
        if n not in by_size:
            by_size[n] = []
        by_size[n].append(r)
    
    # è¯¦ç»†åˆ†ææ¯ä¸ªè§„æ¨¡
    print("\n### æŒ‰é—®é¢˜è§„æ¨¡åˆ†æ ###")
    print("\nè§„æ¨¡  å¹³å‡è¿‘ä¼¼æ¯”  æœ€å·®è¿‘ä¼¼æ¯”  å¹³å‡åŠ é€Ÿ   å¹³å‡ä»·å€¼æŸå¤±  é€‰æ‹©å·®å¼‚")
    print("-" * 70)
    
    for n in sorted(by_size.keys()):
        group = by_size[n]
        
        ratios = [r['approximation_ratio'] for r in group]
        speedups = [r['speedup'] for r in group]
        value_losses = [r['value_loss_percent'] for r in group]
        items_diffs = [r['items_diff'] for r in group]
        
        print(f"{n:4d}  {statistics.mean(ratios):10.3f}  {min(ratios):10.3f}  "
              f"{statistics.mean(speedups):8.1f}x  {statistics.mean(value_losses):11.1f}%  "
              f"{statistics.mean(items_diffs):8.1f}")
    
    # æ€»ä½“ç»Ÿè®¡
    all_ratios = [r['approximation_ratio'] for r in results]
    all_speedups = [r['speedup'] for r in results]
    all_memory_ratios = [r['memory_ratio'] for r in results]
    all_trace_lengths = [r['avg_trace_length'] for r in results if r['avg_trace_length'] > 0]
    
    print(f"\n### æ€»ä½“ç»Ÿè®¡ ###")
    print(f"æ ·æœ¬æ•°é‡: {len(results)}")
    print(f"å¹³å‡è¿‘ä¼¼æ¯”: {statistics.mean(all_ratios):.4f} Â± {statistics.stdev(all_ratios):.4f}")
    print(f"è¿‘ä¼¼æ¯”èŒƒå›´: [{min(all_ratios):.4f}, {max(all_ratios):.4f}]")
    print(f"å››åˆ†ä½æ•°: Q1={statistics.quantiles(all_ratios, n=4)[0]:.4f}, "
          f"Q2={statistics.quantiles(all_ratios, n=4)[1]:.4f}, "
          f"Q3={statistics.quantiles(all_ratios, n=4)[2]:.4f}")
    print(f"æœ€å·®è¿‘ä¼¼æ¯”: {min(all_ratios):.4f}")
    print(f"è¶…è¿‡ç†è®ºä¸‹ç•Œ({THEORETICAL_BOUND:.3f})çš„æ¯”ä¾‹: {sum(1 for r in all_ratios if r >= THEORETICAL_BOUND)/len(all_ratios)*100:.1f}%")
    print(f"\nå¹³å‡é€Ÿåº¦æå‡: {statistics.mean(all_speedups):.1f}x")
    print(f"æœ€å¤§é€Ÿåº¦æå‡: {max(all_speedups):.1f}x")
    print(f"å¹³å‡å†…å­˜èŠ‚çœ: {statistics.mean(all_memory_ratios):.1f}x")
    print(f"å¹³å‡Ï†-traceé•¿åº¦: {statistics.mean(all_trace_lengths):.2f}")
    
    # éªŒè¯ç†è®ºé¢„æµ‹
    print(f"\n### ç†è®ºéªŒè¯ ###")
    print(f"ç†è®ºè¿‘ä¼¼æ¯”ä¸‹ç•Œ: {THEORETICAL_BOUND:.4f}")
    print(f"å®é™…æœ€å·®è¿‘ä¼¼æ¯”: {min(all_ratios):.4f}")
    print(f"è¿åç†è®ºé¢„æµ‹çš„æ¡ˆä¾‹: {sum(1 for r in all_ratios if r < THEORETICAL_BOUND)}")
    
    # è¶‹åŠ¿åˆ†æ
    print(f"\n### è¶‹åŠ¿åˆ†æ ###")
    sizes = sorted(by_size.keys())
    size_ratios = [statistics.mean(r['approximation_ratio'] for r in by_size[n]) for n in sizes]
    size_speedups = [statistics.mean(r['speedup'] for r in by_size[n]) for n in sizes]
    
    # ç®€å•çº¿æ€§å›å½’æ£€æŸ¥è¶‹åŠ¿
    if len(sizes) > 1:
        # è¿‘ä¼¼æ¯”è¶‹åŠ¿
        ratio_trend = (size_ratios[-1] - size_ratios[0]) / (sizes[-1] - sizes[0])
        print(f"è¿‘ä¼¼æ¯”è¶‹åŠ¿: {'æ”¹å–„' if ratio_trend > 0 else 'æ¶åŒ–'} "
              f"(æ–œç‡={ratio_trend:.6f})")
        
        # åŠ é€Ÿæ¯”è¶‹åŠ¿
        speedup_trend = (size_speedups[-1] - size_speedups[0]) / (sizes[-1] - sizes[0])
        print(f"åŠ é€Ÿæ¯”è¶‹åŠ¿: {'å¢é•¿' if speedup_trend > 0 else 'ä¸‹é™'} "
              f"(æ–œç‡={speedup_trend:.3f})")

def save_results(results: List[Dict], filename: str = "results/experiment_results.json"):
    """ä¿å­˜å®éªŒç»“æœ"""
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    
    # æ·»åŠ å…ƒæ•°æ®
    metadata = {
        'phi': PHI,
        'theoretical_bound': THEORETICAL_BOUND,
        'total_experiments': len(results),
        'sizes_tested': sorted(list(set(r['n'] for r in results))),
        'summary': {
            'avg_approximation_ratio': statistics.mean(r['approximation_ratio'] for r in results),
            'avg_speedup': statistics.mean(r['speedup'] for r in results),
            'min_approximation_ratio': min(r['approximation_ratio'] for r in results),
            'max_speedup': max(r['speedup'] for r in results)
        }
    }
    
    output = {
        'metadata': metadata,
        'results': results
    }
    
    with open(filename, 'w') as f:
        json.dump(output, f, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° {filename}")

def run_scaling_test():
    """æµ‹è¯•ç®—æ³•çš„æ‰©å±•æ€§"""
    print("\n### æ‰©å±•æ€§æµ‹è¯• ###")
    print("æµ‹è¯•æå¤§è§„æ¨¡é—®é¢˜...")
    
    large_sizes = [500, 1000]
    for n in large_sizes:
        print(f"\nn = {n}:")
        result = run_single_experiment(n, seed=42)
        
        print(f"  è¿‘ä¼¼æ¯”: {result['approximation_ratio']:.3f}")
        print(f"  é€Ÿåº¦æå‡: {result['speedup']:.1f}x")
        print(f"  Collapseæ—¶é—´: {result['collapse_time']*1000:.1f}ms")
        print(f"  DPæ—¶é—´: {result['dp_time']*1000:.1f}ms")
        print(f"  å†…å­˜æ¯”: {result['memory_ratio']:.1f}x")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŒ CollapseGPT vs åŠ¨æ€è§„åˆ’ - å¤§è§„æ¨¡å®éªŒ ğŸŒŒ")
    print("="*70)
    
    # å®éªŒè®¾ç½®
    sizes = [10, 20, 50, 100, 200]
    trials = 20
    
    print(f"å®éªŒè®¾ç½®:")
    print(f"  é—®é¢˜è§„æ¨¡: {sizes}")
    print(f"  æ¯ä¸ªè§„æ¨¡è¯•éªŒæ¬¡æ•°: {trials}")
    print(f"  æ€»å®éªŒæ•°: {len(sizes) * trials}")
    print(f"  ç†è®ºè¿‘ä¼¼æ¯”ä¸‹ç•Œ: {THEORETICAL_BOUND:.4f}")
    
    # è¿è¡Œä¸»å®éªŒ
    results = run_experiments(sizes, trials)
    
    # åˆ†æç»“æœ
    analyze_results(results)
    
    # ä¿å­˜ç»“æœ
    save_results(results)
    
    # æ‰©å±•æ€§æµ‹è¯•
    run_scaling_test()
    
    print("\n" + "="*70)
    print("âœ¨ å®éªŒå®Œæˆï¼")
    print("\nå…³é”®å‘ç°:")
    print(f"1. å¹³å‡è¿‘ä¼¼æ¯” {statistics.mean(r['approximation_ratio'] for r in results):.3f} è¿œè¶…ç†è®ºä¸‹ç•Œ {THEORETICAL_BOUND:.3f}")
    print(f"2. å¹³å‡é€Ÿåº¦æå‡ {statistics.mean(r['speedup'] for r in results):.0f}xï¼Œä¸”éšè§„æ¨¡å¢é•¿")
    print("3. æ‰€æœ‰ç»“æœéƒ½éªŒè¯äº†ç†è®ºé¢„æµ‹")
    print("4. Collapseæ–¹æ³•å±•ç°äº†ä¼˜ç§€çš„å¯æ‰©å±•æ€§")

if __name__ == "__main__":
    main() 